{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be25b28c",
   "metadata": {},
   "source": [
    "# Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e49a7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, f1_score\n",
    ")\n",
    "\n",
    "# course helpers (already in your repo)\n",
    "from cross_validation import make_train_and_test_row_ids_for_n_fold_cv, train_models_and_calc_scores_for_n_fold_cv\n",
    "\n",
    "np.set_printoptions(threshold=50, linewidth=160, suppress=True)\n",
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "40ad2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5557 entries, 0 to 5556\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   author                         5557 non-null   object \n",
      " 1   title                          5557 non-null   object \n",
      " 2   passage_id                     5557 non-null   int64  \n",
      " 3   text                           5557 non-null   object \n",
      " 4   char_count                     5557 non-null   float64\n",
      " 5   word_count                     5557 non-null   float64\n",
      " 6   sentence_count                 5557 non-null   float64\n",
      " 7   avg_word_length                5557 non-null   float64\n",
      " 8   avg_sentence_length            5557 non-null   float64\n",
      " 9   type_token_ratio               5557 non-null   float64\n",
      " 10  pronoun_freq                   5557 non-null   float64\n",
      " 11  function_words_count           5557 non-null   float64\n",
      " 12  punctuation_frequency          5557 non-null   float64\n",
      " 13  sentiment_polarity             5557 non-null   float64\n",
      " 14  sentiment_subjectivity         5557 non-null   float64\n",
      " 15  readability_Kincaid            5557 non-null   float64\n",
      " 16  readability_ARI                5557 non-null   float64\n",
      " 17  readability_Coleman-Liau       5557 non-null   float64\n",
      " 18  readability_FleschReadingEase  5557 non-null   float64\n",
      " 19  readability_GunningFogIndex    5557 non-null   float64\n",
      " 20  readability_LIX                5557 non-null   float64\n",
      " 21  readability_SMOGIndex          5557 non-null   float64\n",
      " 22  readability_RIX                5557 non-null   float64\n",
      " 23  readability_DaleChallIndex     5557 non-null   float64\n",
      " 24  info_characters_per_word       5557 non-null   float64\n",
      " 25  info_syll_per_word             5557 non-null   float64\n",
      " 26  info_words_per_sentence        5557 non-null   float64\n",
      " 27  info_type_token_ratio          5557 non-null   float64\n",
      " 28  info_characters                5557 non-null   float64\n",
      " 29  info_syllables                 5557 non-null   float64\n",
      " 30  info_words                     5557 non-null   float64\n",
      " 31  info_wordtypes                 5557 non-null   float64\n",
      "dtypes: float64(28), int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "0       \"Yes.... What sort of terms was he on with the...\n",
      "1       Perhaps I should say that it was Mark's  priva...\n",
      "2       \"Well, he had to mark the particular place by ...\n",
      "3       \"I never ought to have asked you,\" said Antony...\n",
      "4       \"And now,\" he said, \"let's try and find out wh...\n",
      "                              ...                        \n",
      "5552    Gervaise looked very humble and nodded her hea...\n",
      "5553    Gervaise, all in a tremble, remained  seated o...\n",
      "5554    A brandied plum occasionally could not  hurt, ...\n",
      "5555    They all looked at each other with this  thoug...\n",
      "5556    When Coupeau remained motionless on his pillow...\n",
      "Name: text, Length: 5557, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.read_csv('x_train.csv')\n",
    "tr_list_of_text = x_train_df['text'].values.tolist()\n",
    "\n",
    "\n",
    "x_train_df.head()          # first rows\n",
    "x_train_df.info()          # column types & non-null counts\n",
    "print(x_train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb6d18",
   "metadata": {},
   "source": [
    "#### Declare tokenize text function from lab 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6b7b905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(raw_text):\n",
    "    ''' Transform a plain-text string into a list of tokens\n",
    "    \n",
    "    We assume that *whitespace* divides tokens.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    raw_text : string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_tokens : list of strings\n",
    "        Each element is one token in the provided text\n",
    "    '''\n",
    "    list_of_tokens = raw_text.split() # split method divides on whitespace by default\n",
    "    for pp in range(len(list_of_tokens)):\n",
    "        cur_token = list_of_tokens[pp]\n",
    "        # Remove punctuation\n",
    "        for punc in ['?', '!', '_', '.', ',', '\"', '/', '--']:\n",
    "            cur_token = cur_token.replace(punc, \"\")\n",
    "        # Turn to lower case\n",
    "        clean_token = cur_token\n",
    "        # Replace the cleaned token into the original list\n",
    "        list_of_tokens[pp] = clean_token\n",
    "    return list_of_tokens\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997daed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# simple default stop list (tweak as needed)\n",
    "DEFAULT_STOPWORDS = {\n",
    "    \"the\", \"or\", \"was\", \"is\", \"and\", \"I\", \"c\"\n",
    "}\n",
    "\n",
    "# precompile a lightweight cleaner: keep letters/numbers and internal apostrophes/hyphens\n",
    "_CLEAN_RE = re.compile(r\"[^\\w'-]+\")  # removes chars other than letters/digits/_/'/-\n",
    "\n",
    "def tokenize_text(raw_text, stopwords=DEFAULT_STOPWORDS, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Transform plain text into a list of tokens:\n",
    "      - lowercase\n",
    "      - strip simple punctuation\n",
    "      - optionally drop stop words\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    raw_text : str\n",
    "    stopwords : set[str]         # custom stop list (lowercase)\n",
    "    remove_stopwords : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "    \"\"\"\n",
    "    if not raw_text:\n",
    "        return []\n",
    "\n",
    "    # split on whitespace, then clean each token\n",
    "    toks = []\n",
    "    for tok in raw_text.split():\n",
    "        tok = _CLEAN_RE.sub(\"\", tok)    # remove punctuation clusters\n",
    "        tok = tok.strip(\"-'\")           # trim stray leading/trailing dashes/apostrophes\n",
    "        if not tok:\n",
    "            continue\n",
    "        if remove_stopwords and tok in stopwords:\n",
    "            continue\n",
    "        toks.append(tok)\n",
    "    return toks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c95643",
   "metadata": {},
   "source": [
    "### Add column \"tokens\" to x_train\n",
    "#### - each row now contains a list of each tokenized word from that samples text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "50a2d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df[\"tokens\"] = x_train_df[\"text\"].astype(str).apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1180f1",
   "metadata": {},
   "source": [
    "## Attempt to filter passage specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "a12716b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dict = dict()\n",
    "x_train_df[\"uniq_tokens\"] = x_train_df[\"tokens\"].apply(set)\n",
    "\n",
    "doc_freq = x_train_df[\"uniq_tokens\"].explode().value_counts()\n",
    "\n",
    "only_once = set(doc_freq[doc_freq == 1].index)\n",
    "\n",
    "unique_dict = {tok: (1 if tok in only_once else 0) for tok in doc_freq.index}\n",
    "\n",
    "\n",
    "x_train_df[\"tokens_noUnique\"] = x_train_df[\"tokens\"].apply(\n",
    "    lambda toks: [t for t in toks if t not in only_once]\n",
    ")\n",
    "\n",
    "# for i in x_train_df:\n",
    "#     for token in np.unique(x_train_df['tokens']):\n",
    "#         if token in unique_dict:\n",
    "#             unique_dict[token] = 0\n",
    "#         else:\n",
    "#             unique_dict[token] = 1\n",
    "\n",
    "\n",
    "\n",
    "# Take dup-free text np.\n",
    "    # Take Word\n",
    "        # check if in Unique\n",
    "            # if in Unique already set value = 0\n",
    "            # if not add to Unique set value = 1 \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# tokens column keeps original casing: list[str] per row\n",
    "s = x_train_df[\"tokens\"]          # or your column name\n",
    "\n",
    "# count, per lowercase form, how often it appears capitalized vs total\n",
    "def is_cap(t): \n",
    "    return t[:1].isupper() and not t.isupper()   # avoid killing acronyms like \"USA\"\n",
    "\n",
    "tot = {}\n",
    "cap = {}\n",
    "for toks in s.dropna():\n",
    "    for t in toks:\n",
    "        tl = t.lower()\n",
    "        tot[tl] = tot.get(tl, 0) + 1\n",
    "        cap[tl] = cap.get(tl, 0) + (1 if is_cap(t) else 0)\n",
    "\n",
    "# mark terms to drop if mostly capitalized (tunable threshold)\n",
    "THRESH = 0.8\n",
    "drop_names = {t for t, c in cap.items() if c / tot[t] >= THRESH and len(t) > 1}\n",
    "\n",
    "# filter each doc; preserve original order\n",
    "x_train_df[\"tokens_noProper\"] = s.apply(\n",
    "    lambda toks: [t for t in toks if t.lower() not in drop_names]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9769fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of unique Tokens: \n",
      "28667\n",
      "\n",
      " TOP 10 TOKENS (with count)\n",
      "11876 of\n",
      "11697 to\n",
      " 8847 a\n",
      " 6418 in\n",
      " 5255 that\n",
      " 4688 he\n",
      " 4184 his\n",
      " 4132 it\n",
      " 3437 with\n",
      " 3378 had\n",
      "\n",
      " BOTTOM 10 TOKENS:\n",
      "    1 whole-hearted\n",
      "    1 squinted\n",
      "    1 undressing\n",
      "    1 saucy\n",
      "    1 brandied\n",
      "    1 absinthe\n",
      "    1 teased\n",
      "    1 hearse\n",
      "    1 lumpy\n",
      "    1 monumental\n"
     ]
    }
   ],
   "source": [
    "token_count_dict = dict()\n",
    "\n",
    "for row in x_train_df['tokens_noProper']:\n",
    "    for token in row:\n",
    "        if not token:   # skip empty tokens caused by punctuation stripping\n",
    "            continue\n",
    "        if token in token_count_dict:\n",
    "            token_count_dict[token] += 1\n",
    "        else:\n",
    "            token_count_dict[token] = 1\n",
    "\n",
    "\n",
    "sorted_tokens = list(sorted(token_count_dict, key=token_count_dict.get, reverse=True))\n",
    "\n",
    "print(\"\\n Number of unique Tokens: \")\n",
    "print(len(sorted_tokens))\n",
    "\n",
    "print(\"\\n TOP 10 TOKENS (with count)\")\n",
    "for w in sorted_tokens[:10]:\n",
    "    print(f\"{token_count_dict[w]:5d} {w}\")\n",
    "\n",
    "print(\"\\n BOTTOM 10 TOKENS:\")\n",
    "for w in sorted_tokens[-10:]:\n",
    "    print(f\"{token_count_dict[w]:5d} {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0703b71",
   "metadata": {},
   "source": [
    "#### Create our finite list of vocab (only tokens that appear > 4 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f1ecad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Vocab size (unfiltered)): 28667\n"
     ]
    }
   ],
   "source": [
    "vocab = [w for w in sorted_tokens ]#if token_count_dict[w] >= 4]\n",
    "print(f\"\\n Vocab size (unfiltered)): {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc93e92",
   "metadata": {},
   "source": [
    "# Featurizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fd39bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_into_feature_vector(token_list, vocab_dict):\n",
    "    \"\"\"Return a count vector for a provided *tokenized* text (list of tokens).\"\"\"\n",
    "    vocabulary_size = len(vocab_dict)\n",
    "    counts_vector = np.zeros(vocabulary_size, dtype=int)\n",
    "    \n",
    "    for token in token_list:\n",
    "        if token in vocab_dict:\n",
    "            vocab_index = vocab_dict[token]\n",
    "            counts_vector[vocab_index] += 1\n",
    "    return counts_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c20ff9",
   "metadata": {},
   "source": [
    "#### Test featurization function with first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b9c0472d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(transform_text_into_feature_vector(x_train_df[\"tokens_noProper\"].iloc[0], token_count_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be4b1e",
   "metadata": {},
   "source": [
    "# Using Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177cf81",
   "metadata": {},
   "source": [
    "#### Load y_train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5b176c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique coarse labels in y_train: ['Key Stage 2-3' 'Key Stage 4-5']\n",
      "y_tr_N shape: (5557,)\n",
      "Class counts: 2509 (KS2-3), 3048 (KS4-5)\n",
      "First 10 labels: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load labels\n",
    "y_train_df = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "# Basic column checks\n",
    "assert \"Coarse Label\" in y_train_df.columns, \"Missing 'Coarse Label' in y_train.csv\"\n",
    "assert len(y_train_df) == len(x_train_df), \"Row counts differ; are files aligned the same way?\"\n",
    "\n",
    "# Peek unique coarse labels\n",
    "print(\"Unique coarse labels in y_train:\", y_train_df[\"Coarse Label\"].unique())\n",
    "\n",
    "# Map to {0,1}\n",
    "label_map = {\"Key Stage 2-3\": 0, \"Key Stage 4-5\": 1}\n",
    "y_coarse = y_train_df.iloc[:, 3]            # 4th column = 'Coarse Label'\n",
    "y_tr_N = y_coarse.map(label_map).to_numpy() # int labels\n",
    "\n",
    "# Sanity checks\n",
    "assert y_tr_N.shape[0] == len(x_train_df), \"Label length mismatch\"\n",
    "assert not np.isnan(y_tr_N).any(), \"Found NaNs after mapping — unexpected label values?\"\n",
    "\n",
    "# Class counts + preview\n",
    "print(\"y_tr_N shape:\", y_tr_N.shape)\n",
    "print(\"Class counts:\", (y_tr_N == 0).sum(), \"(KS2-3),\", (y_tr_N == 1).sum(), \"(KS4-5)\")\n",
    "print(\"First 10 labels:\", y_tr_N[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf67c9",
   "metadata": {},
   "source": [
    "# Building BOW from only Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "79a5db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_vocab_from_ids(train_ids, min_count=1):\n",
    "    \"\"\"Build a vocabulary from TRAIN rows only.\"\"\"\n",
    "    tok_count = {}\n",
    "    for i in train_ids:\n",
    "        # grab the tokenized list of words from each row\n",
    "        toks = x_train_df.loc[i, 'tokens_noProper']\n",
    "        for t in toks:\n",
    "            # skip empty strings/tokens\n",
    "            if t:\n",
    "                tok_count[t] = tok_count.get(t, 0) + 1\n",
    "\n",
    "    # only keep tokens that meet frequency threshold\n",
    "    vocab = [token for token, c in tok_count.items() if c >= min_count]\n",
    "    vocab.sort()\n",
    "    # return vocab as list of tokens\n",
    "    return vocab\n",
    "\n",
    "# makes vocab dict from vocab list, key value = {word, count}\n",
    "def make_vocab_dict(vocab):\n",
    "    # Map token -> column index\n",
    "    vocab_dict = dict()\n",
    "    for vocab_id, tok in enumerate(vocab):\n",
    "        vocab_dict[tok] = vocab_id\n",
    "    return vocab_dict\n",
    "\n",
    "# Function to build feature matrix\n",
    "def featurize_ids_to_matrix(row_ids, vocab_dict):\n",
    "    # Build (num rows, V) matrix using transform_text_into_feature_vector\n",
    "\n",
    "    # Num features (num unique tokens)\n",
    "    V = len(vocab_dict)\n",
    "    # Initialize feature matrix\n",
    "    X = np.zeros((len(row_ids), V), dtype=int)\n",
    "\n",
    "    # iterate over input rows with their position in X -> build feature matrix\n",
    "    for rr, idx in enumerate(row_ids):\n",
    "        # grab token list for this document\n",
    "        tokens = x_train_df.loc[idx, 'tokens_noProper']\n",
    "        # use helper function to convert to feature vector\n",
    "        X[rr] = transform_text_into_feature_vector(tokens, vocab_dict)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2158f",
   "metadata": {},
   "source": [
    "# Finding Best Model: K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "24ffa8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1e-05 | mean AUROC=0.6832 | folds=[0.6682 0.6714 0.6988 0.7004 0.6774]\n",
      "C= 3e-05 | mean AUROC=0.6853 | folds=[0.6699 0.6736 0.7007 0.7027 0.6793]\n",
      "C= 0.0001 | mean AUROC=0.6910 | folds=[0.6755 0.6799 0.706  0.7088 0.6851]\n",
      "C= 0.0003 | mean AUROC=0.7029 | folds=[0.687  0.6926 0.7175 0.7205 0.6971]\n",
      "C= 5e-05 | mean AUROC=0.6872 | folds=[0.6718 0.6756 0.7021 0.7049 0.6815]\n",
      "C= 0.001 | mean AUROC=0.7209 | folds=[0.7074 0.7128 0.7341 0.7364 0.714 ]\n",
      "C= 0.0031623 | mean AUROC=0.7392 | folds=[0.7298 0.7362 0.7497 0.7516 0.7286]\n",
      "C= 0.01 | mean AUROC=0.7527 | folds=[0.7434 0.7542 0.76   0.764  0.7417]\n",
      "C= 0.031623 | mean AUROC=0.7590 | folds=[0.7457 0.761  0.7659 0.7724 0.7502]\n",
      "C= 0.1 | mean AUROC=0.7576 | folds=[0.7373 0.7579 0.7669 0.7723 0.7537]\n",
      "C= 0.31623 | mean AUROC=0.7503 | folds=[0.7274 0.7448 0.7623 0.7648 0.7521]\n",
      "C= 1 | mean AUROC=0.7419 | folds=[0.7156 0.7333 0.7546 0.7575 0.7484]\n",
      "C= 3.1623 | mean AUROC=0.7369 | folds=[0.7092 0.7282 0.7518 0.7511 0.7444]\n",
      "C= 10 | mean AUROC=0.7333 | folds=[0.706  0.7235 0.748  0.7466 0.7421]\n",
      "\n",
      "Best C: 0.03162277660168379 | best mean val AUROC: 0.7590394261063594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from cross_validation import make_train_and_test_row_ids_for_n_fold_cv\n",
    "\n",
    "num_examples = len(x_train_df)\n",
    "all_row_indices = np.arange(num_examples)\n",
    "\n",
    "# C grid of values to sweep\n",
    "C_grid = np.r_[1e-5, 3e-5, 1e-4, 3e-4, 5e-5, np.logspace(-3, 1, 9)]\n",
    "\n",
    "# Using our homework function to make K folds\n",
    "train_ids_per_fold, val_ids_per_fold = make_train_and_test_row_ids_for_n_fold_cv(\n",
    "    n_examples=num_examples, n_folds=5, random_state=0\n",
    ")\n",
    "\n",
    "cv_summary = []\n",
    "per_C_fold_aurocs = {}\n",
    "\n",
    "# Sweep across c_values using K-fold\n",
    "for c_value in C_grid:\n",
    "    fold_aurocs = []\n",
    "    for fold_index in range(len(train_ids_per_fold)):\n",
    "        train_indices = train_ids_per_fold[fold_index]\n",
    "        val_indices   = val_ids_per_fold[fold_index]\n",
    "\n",
    "        # vocabulary from training data only (doesn't leak w/ validation)\n",
    "        vocabulary  = build_vocab_from_ids(train_indices, min_count=1)\n",
    "        vocab_index = make_vocab_dict(vocabulary)\n",
    "\n",
    "        # featurize train/val with this fold's vocabulary\n",
    "        X_train_fold = featurize_ids_to_matrix(train_indices, vocab_index)\n",
    "        X_val_fold   = featurize_ids_to_matrix(val_indices,   vocab_index)\n",
    "\n",
    "        y_train_fold = y_tr_N[train_indices]\n",
    "        y_val_fold   = y_tr_N[val_indices]\n",
    "\n",
    "        # train logistic regression\n",
    "        clf = sklearn.linear_model.LogisticRegression(\n",
    "            C=c_value, penalty=\"l2\", solver=\"lbfgs\",\n",
    "            max_iter=5000, tol=1e-3, random_state=0\n",
    "        )\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # AUROC on validation fold (project metric)\n",
    "        val_prob_pos = clf.predict_proba(X_val_fold)[:, 1]\n",
    "        fold_aurocs.append(roc_auc_score(y_val_fold, val_prob_pos))\n",
    "\n",
    "\n",
    "    # Used chat to make clean print display per C_Val\n",
    "    mean_val_auroc = float(np.mean(fold_aurocs))\n",
    "    per_C_fold_aurocs[c_value] = fold_aurocs\n",
    "    cv_summary.append((c_value, mean_val_auroc))\n",
    "    print(\n",
    "        f\"C={c_value: .5g} | mean AUROC={mean_val_auroc:.4f} \"\n",
    "        f\"| folds={np.array2string(np.array(fold_aurocs), precision=4)}\"\n",
    "    )\n",
    "\n",
    "best_C, best_mean_auroc = max(cv_summary, key=lambda item: item[1])\n",
    "print(\"\\nBest C:\", best_C, \"| best mean val AUROC:\", best_mean_auroc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5b474",
   "metadata": {},
   "source": [
    "# Run best model on ALL Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a1e8fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.8137484254093935\n",
      "Final AUROC: 0.8990822017116334\n",
      "Final vocabulary size: 7611\n"
     ]
    }
   ],
   "source": [
    "all_indices = np.arange(len(x_train_df))\n",
    "final_vocabulary   = build_vocab_from_ids(all_indices, min_count=4)\n",
    "final_vocab_index  = make_vocab_dict(final_vocabulary)\n",
    "X_all_train        = featurize_ids_to_matrix(all_indices, final_vocab_index)\n",
    "\n",
    "clf_final = sklearn.linear_model.LogisticRegression(\n",
    "    C=best_C, penalty=\"l2\", solver=\"lbfgs\",\n",
    "    max_iter=5000, tol=1e-3, random_state=0\n",
    ")\n",
    "clf_final.fit(X_all_train, y_tr_N)\n",
    "\n",
    "print(\"Final accuracy:\", clf_final.score(X_all_train, y_tr_N))\n",
    "print(\"Final AUROC:\",\n",
    "      roc_auc_score(y_tr_N, clf_final.predict_proba(X_all_train)[:, 1]))\n",
    "print(\"Final vocabulary size:\", len(final_vocabulary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f93c88",
   "metadata": {},
   "source": [
    "## Visualize top weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b864908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most negative:\n",
      "  -0.3626  It's\n",
      "  -0.3614  talk\n",
      "  -0.3520  asked\n",
      "  -0.3036  Doctor\n",
      "  -0.3017  story\n",
      "  -0.3002  It\n",
      "  -0.2992  minutes\n",
      "  -0.2943  We\n",
      "  -0.2760  He\n",
      "  -0.2692  years\n",
      "  -0.2657  So\n",
      "  -0.2653  right\n",
      "  -0.2612  boys\n",
      "  -0.2581  uncle\n",
      "  -0.2581  There\n",
      "  -0.2555  She\n",
      "  -0.2529  knew\n",
      "  -0.2515  school\n",
      "  -0.2465  feet\n",
      "  -0.2378  D'Artagnan\n",
      "\n",
      "Most positive:\n",
      "   0.3450  Sir\n",
      "   0.3336  K\n",
      "   0.3013  therefore\n",
      "   0.2531  almost\n",
      "   0.2442  unto\n",
      "   0.2434  which\n",
      "   0.2422  husband\n",
      "   0.2079  court\n",
      "   0.2052  hath\n",
      "   0.2033  women\n",
      "   0.2013  death\n",
      "   0.2005  lawyer\n",
      "   0.1995  noble\n",
      "   0.1983  Who\n",
      "   0.1956  When\n",
      "   0.1926  lord\n",
      "   0.1858  To\n",
      "   0.1831  Thou\n",
      "   0.1785  eye\n",
      "   0.1750  o\n"
     ]
    }
   ],
   "source": [
    "weights = clf_final.coef_[0]\n",
    "sorted_indices = np.argsort(weights)\n",
    "top_k = 20\n",
    "\n",
    "print(\"\\nMost negative:\")\n",
    "for index in sorted_indices[:top_k]:\n",
    "    print(f\"{weights[index]:9.4f}  {final_vocabulary[index]}\")\n",
    "\n",
    "print(\"\\nMost positive:\")\n",
    "for index in sorted_indices[-top_k:][::-1]:\n",
    "    print(f\"{weights[index]:9.4f}  {final_vocabulary[index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddef3d0",
   "metadata": {},
   "source": [
    "# Run Best Model on Test Data -> Outputs yproba1__test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1fd94608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved yproba1_test.txt | test shape: (1197,) | first 5: [0.8512277  0.88107835 0.84904821 0.79808213 0.88156887]\n"
     ]
    }
   ],
   "source": [
    "# Train final model on all training data (already built in previous cell) and score x_test\n",
    "# Assumes the following already exist from the previous cell:\n",
    "# all_indices, final_vocabulary, final_vocab_index, X_all_train, y_tr_N, best_C\n",
    "# Also assumes tokenize_text and transform_text_into_feature_vector are defined.\n",
    "\n",
    "# 1) Load and tokenize x_test exactly like x_train\n",
    "x_test_df = pd.read_csv(\"x_test.csv\")\n",
    "x_test_df[\"tokens\"] = x_test_df[\"text\"].astype(str).apply(tokenize_text)\n",
    "\n",
    "# 2) Featurize x_test using the SAME final_vocab_index\n",
    "num_test = len(x_test_df)\n",
    "V = len(final_vocab_index)\n",
    "X_all_test = np.zeros((num_test, V), dtype=int)\n",
    "for row_pos in range(num_test):\n",
    "    tokens_row = x_test_df.loc[row_pos, \"tokens\"]\n",
    "    X_all_test[row_pos] = transform_text_into_feature_vector(tokens_row, final_vocab_index)\n",
    "\n",
    "# 3) Fit final Logistic Regression and produce probabilities for leaderboard\n",
    "final_clf = sklearn.linear_model.LogisticRegression(C=best_C, penalty=\"l2\", solver=\"lbfgs\", max_iter=5000, tol=1e-3, random_state=0)\n",
    "final_clf.fit(X_all_train, y_tr_N)\n",
    "yproba_test = final_clf.predict_proba(X_all_test)[:, 1]\n",
    "\n",
    "# 4) Save to disk (one probability per line)\n",
    "np.savetxt(\"yproba1_test.txt\", yproba_test, fmt=\"%.6f\")\n",
    "\n",
    "print(\"Saved yproba1_test.txt\", \"| test shape:\", yproba_test.shape, \"| first 5:\", yproba_test[:5])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_25s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
